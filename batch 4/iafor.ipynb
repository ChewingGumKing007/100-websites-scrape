{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575d6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: ChewingGumKing_OJF\n",
    "\"\"\"\n",
    "\n",
    "#loads necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyperclip as pc\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from random import randint\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1077874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver=webdriver.Chrome(r'C:\\Users\\840 g3\\Desktop\\chromedriver.exe')\n",
    "from selenium import webdriver \n",
    "\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "# linux only\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "#chrome_options.headless = True \n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\840 g3\\Desktop\\chromedriver.exe',options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c805126",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://iafor.org/conferences/'\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "soup = bs(driver.page_source,'lxml')\n",
    "cards=soup.find_all('div',{'class':re.compile('conference-card post type-post.+')})\n",
    "len(cards)\n",
    "\n",
    "sanp=[]\n",
    "for m in cards:\n",
    "# for k in range(1,22):\n",
    "#     driver.switch_to.window(driver.window_handles[k])\n",
    "#     time.sleep(1)\n",
    "#     soupn=bs(driver.page_source,'lxml')\n",
    "    tit=m.h2.text\n",
    "    link=m.find('a')['href']\n",
    "    datloc=m.find('div',{'class':'conference-card-dates-and-location'}).text\n",
    "    dat,loc=[a.strip() for a in datloc.split('|')]\n",
    "    sanp.append([tit,link,datloc,dat,loc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f2b330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "iafor=[]\n",
    "for m in cards:\n",
    "# for k in range(1,22):\n",
    "#     driver.switch_to.window(driver.window_handles[k])\n",
    "#     time.sleep(1)\n",
    "#     soupn=bs(driver.page_source,'lxml')\n",
    "    title=m.h2.text\n",
    "    link=m.find('a')['href']\n",
    "    datloc=m.find('div',{'class':'conference-card-dates-and-location'}).text\n",
    "    #driver.get(link)\n",
    "    time.sleep(5)\n",
    "    #soupn=bs(driver.page_source,'lxml')\n",
    "    dat,loc=[a.strip() for a in datloc.split('|')]\n",
    "    for m in ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']:\n",
    "        if m in dat:\n",
    "            dat=dat.replace(m,'')\n",
    "    dat=dat.replace('–','-').replace('|','').replace('to','-').replace('TO','-').strip().replace('Oc-ber','October').replace('OC-BER','OCTOBER')\n",
    "    if '(' in dat:\n",
    "        dat=dat.split('(')[0].strip()\n",
    "    if dat=='':\n",
    "        start_date=end_date=''\n",
    "    else:\n",
    "        mad=dat\n",
    "        #('September 8, 2022 I The Ritz-Carlton, Beijing',\n",
    "    if re.search('[A-Sa-z]{3,9}\\s?\\d{1,2}\\s+\\d{4}\\s?[A-Za-z]+\\s?[A-Za-z]+\\s?[A-Za-z]+',mad.replace(',','')):\n",
    "        #print('juice')\n",
    "        tad=re.search('[A-Sa-z]{3,9}\\s?\\d{1,2}\\s+\\d{4}',mad.replace(',','')).group()\n",
    "        mad=tad\n",
    "        st=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "        en=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "    elif '-' in mad:\n",
    "        st=mad.split('-')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "        en=mad.split('-')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "    elif 'and'in mad:\n",
    "        st=mad.split('and')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "        en=mad.split('and')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "    elif '&' in mad:\n",
    "        st=mad.split('&')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "        en=mad.split('&')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "    else:\n",
    "        #print(mad)\n",
    "        st=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "        en=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "\n",
    "    if any(c.isalpha() for c in st)==False:\n",
    "    #      print('leg')\n",
    "        pa=re.search('[A-Sa-z]+\\W+(\\d{4})',en)#, maxsplit=0)\n",
    "        sapa=pa.group()\n",
    "        start=st+' '+sapa\n",
    "        end=en\n",
    "    #                        02        April      2022\n",
    "    elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}\\s\\d{4}',st):\n",
    "     #   print('awujale')\n",
    "        start=st\n",
    "        end=en\n",
    "\n",
    "    #*                        April       02      2022\n",
    "    elif re.search('[A-Sa-z]{3,9}\\s\\d{1,2}\\s+\\d{4}',st):\n",
    "    #       print('ala')\n",
    "        pa=re.search('(\\d{4})',st).group()\n",
    "        sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "        ta=re.search('(\\d{1,2})',st).group()\n",
    "        start=ta+' '+sa+' '+pa\n",
    "        #\n",
    "        ba=re.search('(\\d{4})',en).group()\n",
    "        ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "        da=re.search('(\\d{1,2})',en).group()\n",
    "        end=da+' '+ca+' '+ba     \n",
    "\n",
    "    #                      02     2022\n",
    "    elif re.search('\\d{1,2}\\s+\\d{4}',en):\n",
    "    #      print('kum')\n",
    "        pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "        sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "        ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "        start=ta+' '+sa+' '+pa\n",
    "        #\n",
    "        ba=re.search('(\\d{4})',en).group()\n",
    "        ca=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "        da=re.search('(\\d{1,2})',en).group()\n",
    "        end=da+' '+ca+' '+ba\n",
    "\n",
    "    #                      02         April\n",
    "    elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}',st):\n",
    "    #        print('is')\n",
    "        pa=re.search('(\\d{4})',en)#, maxsplit=0)\n",
    "        sapa=pa.group()\n",
    "        start=st+' '+sapa\n",
    "        end=en\n",
    "\n",
    "    #*                      April           02\n",
    "    elif re.search('[A-Sa-z]{3,9}\\s+\\d{1,2}',st):\n",
    "    #      print('bad')\n",
    "        pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "        sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "        ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "        start=ta+' '+sa+' '+pa\n",
    "        #\n",
    "        ba=re.search('(\\d{4})',en).group()\n",
    "        ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "        da=re.search('(\\d{1,2})',en).group()\n",
    "        end=da+' '+ca+' '+ba\n",
    "\n",
    "    else:\n",
    "    #     print('shik')\n",
    "        start=end=''\n",
    "    if start=='':\n",
    "        start_date=end_date=''\n",
    "    else:\n",
    "        pick=[start, end]\n",
    "        try:\n",
    "            spl_dt_obj = [datetime.strptime(v.strip(), '%d %B %Y') for v in pick]\n",
    "        except:\n",
    "            spl_dt_obj = [datetime.strptime(v.strip(), '%d %b %Y') for v in pick]\n",
    "        date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "        start_date=date_[0]\n",
    "        end_date=date_[1]   \n",
    "\n",
    "    def gu(luc):\n",
    "        google_url_for_location=\"https://www.google.com/search?q=\"+luc+\"&oq=\"+luc+\"&num=1\"\n",
    "        time.sleep(randint(0,3))\n",
    "        driver.get(google_url_for_location)\n",
    "        time.sleep(4)\n",
    "        try:\n",
    "            google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "        except:\n",
    "            try:\n",
    "                google_map_url=driver.find_element_by_class_name('Xm7sWb').click()\n",
    "            except:\n",
    "                google_map_url=driver.find_element_by_class_name('Lx2b0d').click()\n",
    "        time.sleep(1)\n",
    "        google_map_url=driver.current_url\n",
    "#                 print(google_map_url)\n",
    "        return(google_map_url)\n",
    "        ######################################\n",
    "    def get_google_map_url(location):\n",
    "        try:\n",
    "            return(gu(location))\n",
    "        except:\n",
    "            sha=location.split(',')\n",
    "            try:\n",
    "                gu(sha[-3])\n",
    "            except:\n",
    "                try:\n",
    "                    gu(sha[-2])\n",
    "                except:\n",
    "                    try:\n",
    "                        gu(sha[-1])\n",
    "                    except Exception as e:\n",
    "                        print(location, \"; url didn't go through\")\n",
    "                        print(e)\n",
    "                        return(\"\")\n",
    "\n",
    "\n",
    "    def countr(locale):\n",
    "        try:\n",
    "            google_url_for_location=\"https://www.google.com/search?q=\"+locale+\"&oq=\"+locale+\"&num=1\"\n",
    "            time.sleep(randint(0,3))\n",
    "            driver.get(google_url_for_location)\n",
    "            time.sleep(4)\n",
    "            try:\n",
    "                google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "            except:\n",
    "                try:\n",
    "                    google_map_url=driver.find_element_by_class_name('Xm7sWb').click()\n",
    "                except:\n",
    "                    google_map_url=driver.find_element_by_class_name('Lx2b0d').click()\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                country=driver.find_element_by_class_name('x3AX1-LfntMc-header-title-VdSJob').text\n",
    "            except:\n",
    "                country=driver.find_element_by_class_name('bwoZTb').text\n",
    "#                 print(country)\n",
    "            return(country)\n",
    "        except Exception as e:\n",
    "            print(locale, \";country didn't go through\")\n",
    "            print(e)\n",
    "            return(\"\")\n",
    "\n",
    "    ticket_list=''\n",
    "    org_name='The International Academic Forum (IAFOR)'\n",
    "    org_web='https://iafor.org/'\n",
    "    org_pro='Since 2009, The International Academic Forum (IAFOR) has welcomed over 40,000 academics to its interdisciplinary conferences held around the world. IAFOR has hosted conferences in Tokyo, Osaka, Kobe and Kyoto (Japan), London and Brighton (UK), Barcelona (Spain), New York, Virginia, Rhode Island and Hawaii (USA), Hong Kong (Hong Kong SAR), Singapore, and Dubai (UAE).'\n",
    "    logo=''    \n",
    "    sponsor=''\n",
    "    agendalist=''\n",
    "    type_=''\n",
    "    time_=''\n",
    "    event_info=''\n",
    "    Speakerlist=''\n",
    "    category=''\n",
    "    mail_=''\n",
    "    event_web=link\n",
    "    if 'nline' in loc or 'ff Campus' in loc or loc=='' or loc==' ' or loc=='-' or loc=='Virtual' or 'nspecified' in loc or 'irtual' in loc:\n",
    "        on_off='1'\n",
    "        city=''\n",
    "        venue=''\n",
    "        country=''\n",
    "        googlePlaceUrl=''\n",
    "    else:\n",
    "        on_off='0'\n",
    "        if ',' in loc:\n",
    "            city=loc.split(',')[-2]+', '+loc.split(',')[-1].strip()\n",
    "            country=loc.split(',')[-1].strip()\n",
    "        else:\n",
    "            city=loc\n",
    "            country=countr(city)\n",
    "        venue=loc\n",
    "        googlePlaceUrl=get_google_map_url(venue)\n",
    "\n",
    "    iafor.append([link,title,start_date,end_date,time_,event_info,ticket_list,\n",
    "                     org_pro,org_name,org_web,logo,sponsor,agendalist,\n",
    "                     type_,category,city,country,venue,event_web,googlePlaceUrl,mail_,\n",
    "                     Speakerlist,on_off])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e072f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbd2e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iafor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e2e7aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iafor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749dc9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dusted\n"
     ]
    }
   ],
   "source": [
    "iafor_dict=iafor\n",
    "\n",
    "\n",
    "iafor_df= pd.DataFrame(columns=['scrappedUrl','eventname','startdate','enddate','timing','eventinfo','ticketlist','orgProfile','orgName','orgWeb','logo','sponsor','agendalist','type','category','city','country','venue','event_website','googlePlaceUrl','ContactMail','Speakerlist','online_event'],data=iafor_dict)\n",
    "iafor_df.to_csv(\"iafor.tsv\", sep = '\\t',index=False)\n",
    "print('Dusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932beb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f18d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b29c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# s=1\n",
    "# for k in sanp:\n",
    "#     #time.sleep(1)\n",
    "#     driver.execute_script(\"window.open('');\")\n",
    "#     driver.switch_to.window(driver.window_handles[s])\n",
    "#     driver.get(k[1])\n",
    "#     s+=1\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6112bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.switch_to.window(driver.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89980c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truce=[]\n",
    "# for k in range(1,22):\n",
    "#     driver.switch_to.window(driver.window_handles[k])\n",
    "#     time.sleep(1)\n",
    "#     soupn=bs(driver.page_source,'lxml')\n",
    "    \n",
    "#     try:\n",
    "#         info=' '.join(soupn.find('div',{'class':'my-6 text-lg leading-relaxed'}).text.split())\n",
    "#     except:\n",
    "#         info=' '.join(soupn.find('div',{'class':'wysiwyg-content'}).findChild().text.split())\n",
    "#         if ':' in info:\n",
    "#             info='.'.join(info.split('.')[:-1])+'.'\n",
    "#         if 'Click here' in info:\n",
    "#             info=info.split('Click here')[0].strip()\n",
    "#     #**************************\n",
    "#     try:\n",
    "#         mam=' '.join(soupn.find('div',{'class':'my-12'}).get_text(separator='}').split())\n",
    "#         tida=mam.split('} }')[0].replace('–','-')\n",
    "#         strt,enrt=tida.split('}')\n",
    "#         das,tis=strt.split('|')\n",
    "#         dae,tie=enrt.split('|')\n",
    "#         da=das+'-'+dae\n",
    "#         ti=tis+'-'+tie\n",
    "#     except:\n",
    "#         sham=soupn.find('div',{'class':'filterable-list--simple-two'}).text\n",
    "#         diy=soupn.find_all('div',{'class':'filterable-list__row'})\n",
    "#         if 'Time:' in sham:\n",
    "#             for o in diy:\n",
    "#                 if 'Time:' in str(o):\n",
    "#                     ti=' '.join(o.find_all('div',{'class':'filterable-list__cell'})[1].text.replace('–','-').split()).strip()\n",
    "#                     if '|' in ti:\n",
    "#                         try:\n",
    "#                             ti=ti.split('|')[0].split('):')[1].strip()\n",
    "#                         except:\n",
    "#                             ti=ti.split('|')[0].strip()\n",
    "#                 elif 'Date:' in str(o):\n",
    "#                     da=' '.join(o.find_all('div',{'class':'filterable-list__cell'})[1].text.replace('–','-').split()).strip()\n",
    "#                 #tida=ti+'|'+da\n",
    "#         else:\n",
    "#             for o in diy:\n",
    "#                 if 'Date:' in str(o):\n",
    "#                     tida=' '.join(o.find_all('div',{'class':'filterable-list__cell'})[1].text.replace('–','-').split())\n",
    "            \n",
    "#             if '|' in tida:\n",
    "\n",
    "#                 ii=tida.split('|')\n",
    "#                 da=ii[0].strip()\n",
    "#                 if '-' in da:\n",
    "        \n",
    "#                     da=da.split('-')[0].strip()\n",
    "        \n",
    "#                 if ';' in ii[1]:\n",
    "#                     ti=ii[1].split(';')[0].strip()\n",
    "#                 else:\n",
    "#                     ti=ii[1].split(',')[0].strip()\n",
    "#             else:\n",
    "#                 ii=tida.split('-')\n",
    "#                 da=ii[0].strip()\n",
    "#                 if ';' in ii[1]:\n",
    "#                     ti=ii[1].split(';')[0].strip()\n",
    "#                 else:\n",
    "#                     ti=ii[1].split(',')[0].strip()\n",
    "#     for f in ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']:\n",
    "#         if f in da:\n",
    "#             da=da.replace(f,'').replace(',','').strip()\n",
    "#     dat=da.replace(',','').replace('.','').replace('  ',' ').replace('Sept','September').strip()\n",
    "#     if '-' in dat:\n",
    "#         st=dat.split('-')[0].strip()\n",
    "#         en=dat.split('-')[1].strip()\n",
    "#     elif '/' in dat:\n",
    "#         dg=dat.split(' ')\n",
    "#         st,en=dg[0],dg[-1]\n",
    "#     else:\n",
    "#         st=en=dat\n",
    "#     #change ti format\n",
    "#     ti=ti.replace('.','').upper().replace(' AM','AM').replace(' PM','PM')\n",
    "\n",
    "#     #\n",
    "#     if '-' in ti:\n",
    "#         ra=ti.split('-')[0].strip()\n",
    "#         ma=ti.split('-')[1].strip()\n",
    "#         try:\n",
    "#             z=ma.split(' ')[1]\n",
    "#             da=ma.split(' ')[0]\n",
    "#         except:\n",
    "#             z=''\n",
    "#             da=ma\n",
    "#     else:\n",
    "#         ra=ti.split(' ')[0].strip()\n",
    "#         da=''\n",
    "#         z=ti.split(' ')[1].strip()\n",
    "# #     if 'AM' in ra or 'PM' in ra:\n",
    "# #         rt=datetime.strptime(da, '%H:%M')\n",
    "# #         da=rt.strftime('%I:%M%p')\n",
    "# #         mt=datetime.strptime(ra, '%H:%M')\n",
    "# #         ra=mt.strftime('%I:%M%p')\n",
    "#     time_st={'type':'general',\n",
    "#              'Start_time':ra,\n",
    "#              'end_time':da,\n",
    "#              'timezone':z,\n",
    "#              'days':'all'\n",
    "\n",
    "#     }\n",
    "#     time_=json.dumps([time_st])\n",
    "#     time_\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #                        02        April      2022\n",
    "#     if re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}\\s\\d{4}',st):\n",
    "#      #   print('awujale')\n",
    "#         start=st\n",
    "#         end=en\n",
    "#     #special case 5/26\n",
    "#     elif '/' in st:\n",
    "#         if len(st.split('/'))==2:\n",
    "#             yr=str(datetime.today().year)\n",
    "#             br=st+' '+yr\n",
    "#             mo=datetime.strptime(br, '%m/%d %Y')\n",
    "#             start=end=str(mo.strftime('%d %B %Y'))\n",
    "#             if '/' not in en:  \n",
    "#                 start=end\n",
    "#             else:\n",
    "#                 tr=en+' '+yr\n",
    "#                 mo=datetime.strptime(tr, '%m/%d %Y')\n",
    "#                 end=str(mo.strftime('%d %B %Y'))\n",
    "        \n",
    "\n",
    "#     #*                        April       02      2022\n",
    "#     elif re.search('[A-Sa-z]{3,9}\\s\\d{1,2}\\s+\\d{4}',st):\n",
    "#     #       print('ala')\n",
    "#         pa=re.search('(\\d{4})',st).group()\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         ba=re.search('(\\d{4})',en).group()\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba     \n",
    "\n",
    "#     #                      02     2022\n",
    "#     elif re.search('\\d{1,2}\\s+\\d{4}',en):\n",
    "#     #      print('kum')\n",
    "#         pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         ba=re.search('(\\d{4})',en).group()\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba\n",
    "\n",
    "#     #                      02         April\n",
    "#     elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}',st):\n",
    "#     #        print('is')\n",
    "#         pa=re.search('(\\d{4})',en)#, maxsplit=0)\n",
    "#         sapa=pa.group()\n",
    "#         start=st+' '+sapa\n",
    "#         end=en\n",
    "\n",
    "#     #*                      April           02\n",
    "#     elif re.search('[A-Sa-z]{3,9}\\s+\\d{1,2}',st):\n",
    "#     #      print('bad')\n",
    "#         try:\n",
    "#             pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "#         except:\n",
    "#             pa=str(datetime.today().year)\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         try:\n",
    "#             ba=re.search('(\\d{4})',en).group()\n",
    "#         except:\n",
    "#             ba=str(datetime.today().year)\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba\n",
    "#     #**\n",
    "#     if start=='':\n",
    "#         start_date=end_date=''\n",
    "#     else:\n",
    "#         pick=[start, end]\n",
    "#         try:\n",
    "#             spl_dt_obj = [datetime.strptime(v, '%d %b %Y') for v in pick]\n",
    "#         except:\n",
    "#             spl_dt_obj = [datetime.strptime(v, '%d %B %Y') for v in pick]\n",
    "#         date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "#         start_date=date_[0]\n",
    "#         end_date=date_[1]\n",
    "\n",
    "#     truce.append([time_,start_date,end_date,info])\n",
    "# truce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bed9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0556c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8452df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
