{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575d6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: ChewingGumKing_OJF\n",
    "\"\"\"\n",
    "\n",
    "#loads necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyperclip as pc\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from random import randint\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1077874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver=webdriver.Chrome(r'C:\\Users\\840 g3\\Desktop\\chromedriver.exe')\n",
    "from selenium import webdriver \n",
    "\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "# linux only\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "# chrome_options.headless = True \n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\840 g3\\Desktop\\chromedriver.exe',options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c805126",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.carhs.de/en/conferences.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d9b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43dee6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=bs(driver.page_source,'lxml')\n",
    "items=soup.find('nav',{'class':'mod_backboneit_navigation_menu mod_navigation block'}).find('ul',{'class':'level_1'}).find_all('li')\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4302a9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.carhs.de/en/safetyupdate-review-japan-overview.html',\n",
       " 'https://www.carhs.de/en/safetyupdate-graz-overview.html',\n",
       " 'https://www.carhs.de/en/the-ADAS-experience-overview.html',\n",
       " 'https://www.carhs.de/en/safetysummit-overview.html',\n",
       " 'https://www.carhs.de/en/human-modeling-overview.html',\n",
       " 'https://www.carhs.de/en/euro-ncap-overview.html',\n",
       " 'https://www.carhs.de/en/leichtbaugipfel-ueberblick.html',\n",
       " 'https://www.carhs.de/en/safetyweek.html',\n",
       " 'https://www.carhs.de/en/praxisconference-pedestrian-protection-overview.html',\n",
       " 'https://www.carhs.de/en/grand-challenge-overview.html',\n",
       " 'https://www.carhs.de/en/praxiskonferenz-heckaufprall-ueberblick.html',\n",
       " 'https://www.carhs.de/en/VT-overview.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards=[]\n",
    "for m in items:\n",
    "    link='https://www.carhs.de/'+m.find('a')['href']\n",
    "    cards.append(link)\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f5c6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# s=1\n",
    "# for k in cards:\n",
    "#     #time.sleep(1)\n",
    "#     driver.execute_script(\"window.open('');\")\n",
    "#     driver.switch_to.window(driver.window_handles[s])\n",
    "#     driver.get(k)\n",
    "#     s+=1\n",
    "# print(s+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a8a5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[1])\n",
    "#     time.sleep(3)\n",
    "soupn=bs(driver.page_source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35aebaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SafetyUpDate Japan is a high-level one-day event focussing on the latest requirements and innovations for automotive safety development. SafetyUpdate Japan supports the young engineers exchange program AC Fund.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(soupn.find('div',{'class':'ce_text last block'}).find('div',{'class':re.compile('message.+')}).p.text.split())#.replace(t,'').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c7097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c182ccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SafetyUpDate Review Japan - Overview - Empowering Engineers',\n",
       "  'August 23, 2022 10:00 (GMT+9) – September 5, 2022 17:00 (GMT+9)',\n",
       "  'On Demand',\n",
       "  'SafetyUpDate Japan is a high-level one-day event focussing on the latest requirements and innovations for automotive safety development. SafetyUpdate Japan supports the young engineers exchange program AC Fund.'],\n",
       " ['SafetyUpDate Graz - Overview - Empowering Engineers',\n",
       "  'September 20 – 21, 2022',\n",
       "  'Graz, Austria',\n",
       "  ''],\n",
       " ['The ADAS Experience - Overview - Empowering Engineers',\n",
       "  'September 22 – 23, 2022',\n",
       "  'Bad Sobernheim, Germany',\n",
       "  ''],\n",
       " ['Automotive Safety Summit Shanghai - Overview - Empowering Engineers',\n",
       "  'October 2022',\n",
       "  'Shanghai, China',\n",
       "  ''],\n",
       " ['Human Modeling - Overview - Empowering Engineers',\n",
       "  'November 16 – 17, 2022',\n",
       "  'Wiesbaden, Germany',\n",
       "  ''],\n",
       " ['Euro NCAP - Overview - Empowering Engineers',\n",
       "  'December 13 – 14, 2022',\n",
       "  'Hanau, Germany',\n",
       "  ''],\n",
       " ['Leichtbau-Gipfel - Überblick - Empowering Engineers',\n",
       "  '2022',\n",
       "  'Vogel Convention Center, Würzburg',\n",
       "  ''],\n",
       " ['SafetyWeek - Empowering Engineers',\n",
       "  'May 23 – 25, 2023',\n",
       "  'Würzburg, Germany',\n",
       "  'May 11, 2022 Interview with Ola Boström, Veoneer'],\n",
       " ['PraxisConference Pedestrian Protection - Overview - Empowering Engineers',\n",
       "  'June 13 – 14, 2023',\n",
       "  'Bergisch Gladbach, Germany',\n",
       "  ''],\n",
       " ['Automotive CAE Grand Challenge - Overview - Empowering Engineers',\n",
       "  '2023',\n",
       "  '',\n",
       "  ''],\n",
       " ['Praxiskonferenz Heckaufprall - Sitze - Whiplash - Empowering Engineers',\n",
       "  '2023',\n",
       "  '',\n",
       "  'Die Konferenz für Praktiker'],\n",
       " ['Virtual Testing - Overview - Empowering Engineers',\n",
       "  '2022',\n",
       "  '',\n",
       "  'Certification and homologation by means of  has been a goal in the automotive industry for quite some time. However progress in this area has been slow. Ever increasing requirements from consumer protection and legal organisations are accelerating the pace for accepted procedures to use virtual testing as an alternative or supplement to physical testing and approval.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carhs=[]\n",
    "for k in range(1,13):\n",
    "    driver.switch_to.window(driver.window_handles[k])\n",
    "#     time.sleep(3)\n",
    "    soupn=bs(driver.page_source,'lxml')\n",
    "    title=' '.join(soupn.find('title').text.split())#.split('-',-1)[0].strip()\n",
    "    datiloc=' '.join(soupn.find('div',{'class':'ce_text first last block'}).text.split())\n",
    "    dat=datiloc.split('|')[0].strip()\n",
    "    try:\n",
    "        loc=datiloc.split('|')[1].strip()\n",
    "    except:\n",
    "        loc=''\n",
    "    try:\n",
    "        info=' '.join(soupn.find('div',{'class':'ce_text last block'}).find('div',{'class':re.compile('message.+')}).p.text.split())\n",
    "    except:\n",
    "        try:\n",
    "            \n",
    "            t=' '.join(soupn.find('div',{'class':'ce_text block'}).find('h1').text.split())   \n",
    "            info=' '.join(soupn.find('div',{'class':'ce_text block'}).text.split()).replace(t,'').strip()\n",
    "        except:\n",
    "            try:\n",
    "                info=' '.join(soupn.find('div',{'class':'ce_text block'}).p.text.split())#.replace(t,'').strip()\n",
    "            except:\n",
    "                info=''\n",
    "    \n",
    "    carhs.append([title,dat,loc,info])\n",
    "carhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153ccc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eebbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "brek=True\n",
    "cards=[]\n",
    "while brek:\n",
    "    url=f'https://www.ox.ac.uk/events-list?page={n}'\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    soup=bs(driver.page_source,'lxml')\n",
    "    car=soup.find_all('div',{'class':'node-event view-mode-ow-listing-teaser'})\n",
    "    \n",
    "    for j in car:\n",
    "        ritle=' '.join(j.find('a').text.split())\n",
    "        web=j.find('a')['href']\n",
    "        link='https://www.ox.ac.uk'+web\n",
    "        lo=j.find('div',{'class':'field-name-field-event-venue'})\n",
    "        dat_dur=' '.join(j.find('span',{'class':'field-name-field-event-date field-type-date'}).text.split())\n",
    "        dat=dat_dur.replace('–','-').replace('|','').replace('to','-').replace('TO','-').strip()\n",
    "        if '(' in dat:\n",
    "            dat=dat.split('(')[0].strip()\n",
    "        if dat=='':\n",
    "            start_date=end_date=''\n",
    "        else:\n",
    "            mad=dat\n",
    "            #try:\n",
    "    #             ma=re.search('([A-Sa-z]+\\W+\\d{1,2}.+\\W+\\d{4}|\\d{1,2}.+\\W+\\d{4})',_date)#, maxsplit=0)\n",
    "    #             mad=ma.group()\n",
    "\n",
    "            if '-' in mad:\n",
    "                st=mad.split('-')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "                en=mad.split('-')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "            elif 'and'in mad:\n",
    "                st=mad.split('and')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "                en=mad.split('and')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "            elif '&' in mad:\n",
    "                st=mad.split('&')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "                en=mad.split('&')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "            else:\n",
    "                st=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "                en=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "            #print(date__,st,en)\n",
    "            ####################\n",
    "            if any(c.isalpha() for c in st)==False:\n",
    "            #      print('leg')\n",
    "                pa=re.search('[A-Sa-z]+\\W+(\\d{4})',en)#, maxsplit=0)\n",
    "                sapa=pa.group()\n",
    "                start=st+' '+sapa\n",
    "                end=en\n",
    "            #                        02        April      2022\n",
    "            elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}\\s\\d{4}',st):\n",
    "             #   print('awujale')\n",
    "                start=st\n",
    "                end=en\n",
    "\n",
    "            #*                        April       02      2022\n",
    "            elif re.search('[A-Sa-z]{3,9}\\s\\d{1,2}\\s+\\d{4}',st):\n",
    "            #       print('ala')\n",
    "                pa=re.search('(\\d{4})',st).group()\n",
    "                sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "                ta=re.search('(\\d{1,2})',st).group()\n",
    "                start=ta+' '+sa+' '+pa\n",
    "                #\n",
    "                ba=re.search('(\\d{4})',en).group()\n",
    "                ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "                da=re.search('(\\d{1,2})',en).group()\n",
    "                end=da+' '+ca+' '+ba     \n",
    "\n",
    "            #                      02     2022\n",
    "            elif re.search('\\d{1,2}\\s+\\d{4}',en):\n",
    "            #      print('kum')\n",
    "                pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "                sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "                ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "                start=ta+' '+sa+' '+pa\n",
    "                #\n",
    "                ba=re.search('(\\d{4})',en).group()\n",
    "                ca=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "                da=re.search('(\\d{1,2})',en).group()\n",
    "                end=da+' '+ca+' '+ba\n",
    "\n",
    "            #                      02         April\n",
    "            elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}',st):\n",
    "            #        print('is')\n",
    "                pa=re.search('(\\d{4})',en)#, maxsplit=0)\n",
    "                sapa=pa.group()\n",
    "                start=st+' '+sapa\n",
    "                end=en\n",
    "\n",
    "            #*                      April           02\n",
    "            elif re.search('[A-Sa-z]{3,9}\\s+\\d{1,2}',st):\n",
    "            #      print('bad')\n",
    "                pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "                sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "                ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "                start=ta+' '+sa+' '+pa\n",
    "                #\n",
    "                ba=re.search('(\\d{4})',en).group()\n",
    "                ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "                da=re.search('(\\d{1,2})',en).group()\n",
    "                end=da+' '+ca+' '+ba\n",
    "\n",
    "            else:\n",
    "            #     print('shik')\n",
    "                start=end=''\n",
    "            if start=='':\n",
    "                start_date=end_date=''\n",
    "            else:\n",
    "                pick=[start, end]\n",
    "                try:\n",
    "                    spl_dt_obj = [datetime.strptime(v, '%d %B %Y') for v in pick]\n",
    "                except:\n",
    "                    spl_dt_obj = [datetime.strptime(v, '%d %b %Y') for v in pick]\n",
    "                date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "                start_date=date_[0]\n",
    "                end_date=date_[1]\n",
    "        cards.append([link,ritle,start_date,end_date,lo])\n",
    "    n+=1\n",
    "    if n==int(2)+1:#lastpage\n",
    "        brek=False\n",
    "#crads=(list(itertools.chain.from_iterable(cards)))\n",
    "print('The total number of items to be scraped is ',len(cards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53024880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253595b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unox_dict=unox\n",
    "\n",
    "\n",
    "unox_df= pd.DataFrame(columns=['scrappedUrl','eventname','startdate','enddate','timing','eventinfo','ticketlist','orgProfile','orgName','orgWeb','logo','sponsor','agendalist','type','category','city','country','venue','event_website','googlePlaceUrl','ContactMail','Speakerlist','online_event'],data=unox_dict)\n",
    "unox_df.to_csv(\"unox.tsv\", sep = '\\t',index=False)\n",
    "print('Dusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932beb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.switch_to.window(driver.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89980c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unox=[]\n",
    "# for k in range(1,31):\n",
    "#     driver.switch_to.window(driver.window_handles[k])\n",
    "\n",
    "#     soupn=bs(driver.page_source,'lxml')\n",
    "#     title=' '.join(soupn.find('header',{'class':'main-title'}).text.split())\n",
    "#     try:\n",
    "#         dat=' '.join(soupn.find('div',{'class':re.compile('field field-name-field-event-date.+')}).find('span',{'class':'field-item-single'}).text.split())\n",
    "#     except:\n",
    "#         dat=''\n",
    "    \n",
    "#     dat=dat.replace('–','-').replace('|','').replace('to','-').replace('TO','-').strip()\n",
    "#     if '(' in dat:\n",
    "#         dat=dat.split('(')[0].strip()\n",
    "#     if dat=='':\n",
    "#         start_date=end_date=''\n",
    "#     else:\n",
    "#         mad=dat\n",
    "#     if '-' in mad:\n",
    "#         st=mad.split('-')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "#         en=mad.split('-')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "#     elif 'and'in mad:\n",
    "#         st=mad.split('and')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "#         en=mad.split('and')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "#     elif '&' in mad:\n",
    "#         st=mad.split('&')[0].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "#         en=mad.split('&')[1].strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "\n",
    "#     else:\n",
    "#         st=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "#         en=mad.strip().replace(',','').replace('nd','').replace('st','').replace('th','').replace('rd','').replace('ugu','ugust')\n",
    "   \n",
    "#     if any(c.isalpha() for c in st)==False:\n",
    "#     #      print('leg')\n",
    "#         pa=re.search('[A-Sa-z]+\\W+(\\d{4})',en)#, maxsplit=0)\n",
    "#         sapa=pa.group()\n",
    "#         start=st+' '+sapa\n",
    "#         end=en\n",
    "#     #                        02        April      2022\n",
    "#     elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}\\s\\d{4}',st):\n",
    "#      #   print('awujale')\n",
    "#         start=st\n",
    "#         end=en\n",
    "\n",
    "#     #*                        April       02      2022\n",
    "#     elif re.search('[A-Sa-z]{3,9}\\s\\d{1,2}\\s+\\d{4}',st):\n",
    "#     #       print('ala')\n",
    "#         pa=re.search('(\\d{4})',st).group()\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         ba=re.search('(\\d{4})',en).group()\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba     \n",
    "\n",
    "#     #                      02     2022\n",
    "#     elif re.search('\\d{1,2}\\s+\\d{4}',en):\n",
    "#     #      print('kum')\n",
    "#         pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         ba=re.search('(\\d{4})',en).group()\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba\n",
    "\n",
    "#     #                      02         April\n",
    "#     elif re.search('\\d{1,2}\\s+[A-Sa-z]{3,9}',st):\n",
    "#     #        print('is')\n",
    "#         pa=re.search('(\\d{4})',en)#, maxsplit=0)\n",
    "#         sapa=pa.group()\n",
    "#         start=st+' '+sapa\n",
    "#         end=en\n",
    "\n",
    "#     #*                      April           02\n",
    "#     elif re.search('[A-Sa-z]{3,9}\\s+\\d{1,2}',st):\n",
    "#     #      print('bad')\n",
    "#         pa=re.search('(\\d{4})',en).group()#, maxsplit=0)\n",
    "#         sa=re.search('([A-Sa-z]{3,9})',st).group()\n",
    "#         ta=re.search('(\\d{1,2})',st).group()\n",
    "\n",
    "#         start=ta+' '+sa+' '+pa\n",
    "#         #\n",
    "#         ba=re.search('(\\d{4})',en).group()\n",
    "#         ca=re.search('([A-Sa-z]{3,9})',en).group()\n",
    "#         da=re.search('(\\d{1,2})',en).group()\n",
    "#         end=da+' '+ca+' '+ba\n",
    "\n",
    "#     else:\n",
    "#     #     print('shik')\n",
    "#         start=end=''\n",
    "#     if start=='':\n",
    "#         start_date=end_date=''\n",
    "#     else:\n",
    "#         pick=[start, end]\n",
    "#         try:\n",
    "#             spl_dt_obj = [datetime.strptime(v, '%d %B %Y') for v in pick]\n",
    "#         except:\n",
    "#             spl_dt_obj = [datetime.strptime(v, '%d %b %Y') for v in pick]\n",
    "#         date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "#         start_date=date_[0]\n",
    "#         end_date=date_[1]\n",
    "\n",
    "   \n",
    "#     try:\n",
    "#         tim=' '.join(soupn.find('div',{'class':re.compile('field field-name-field-event-time.+')}).find('span',{'class':'field-item-single'}).text.split()).upper().replace('TO','-').split('-')#.strip()\n",
    "#     except:\n",
    "#         tim=''\n",
    "#     try:\n",
    "#         tic=' '.join(soupn.find('div',{'class':re.compile('field field-name-field-event-cost.+')}).find('span',{'class':'field-item-single'}).text.split())\n",
    "#     except:\n",
    "#         tic=''\n",
    "#     if tic!='':\n",
    "#         if 'Free' in tic or tic=='Free':\n",
    "#             ty='free'\n",
    "#             am=''\n",
    "#             cu=''\n",
    "\n",
    "#         elif re.search('\\$?\\£?\\€?\\W?[0-9]+',tic).group():\n",
    "#             ty='paid'\n",
    "#             am=re.search('[0-9]+',tic).group()\n",
    "#             cu=re.search('\\$?\\£?\\€?',tic).group()\n",
    "#         ticket=[{'type': ty,\n",
    "#                  'price':am,\n",
    "#                  'currency': cu}]\n",
    "#         ticket_list=json.dumps(ticket,ensure_ascii=False)\n",
    "#     else:\n",
    "#         ticket_list=''\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "#         event_info=' '.join(soupn.find('div',{'class':re.compile('field field-name-field-body.+')}).find('span',{'class':'field-item-single'}).text.split())\n",
    "#     except:\n",
    "#         event_info=''\n",
    "#     try:\n",
    "#         event_web=soupn.find('div',{'class':re.compile('field field-name-field-further-information.+')}).find('a')['href']\n",
    "#     except:\n",
    "#         event_web=''\n",
    "\n",
    "        \n",
    "#     if tim=='':\n",
    "#         time_=''\n",
    "        \n",
    "#     else:\n",
    "#         #print('azure')\n",
    "#         if len(tim)==2:\n",
    "#             stt=datetime.strptime(tim[0].strip(), '%H:%M').strftime('%I:%M%p')\n",
    "#             ent=datetime.strptime(tim[1].strip(), '%H:%M').strftime('%I:%M%p')\n",
    "#             z=''\n",
    "#         elif len(tim)==1:\n",
    "#             stt=datetime.strptime(tim[0].strip(), '%H:%M').strftime('%I:%M%p')\n",
    "#             ent=''\n",
    "#             z=''\n",
    "#         time_st={   \n",
    "#             'type':'general',\n",
    "#             'Start_time':stt,\n",
    "#             'end_time':ent,\n",
    "#             'timezone':z,\n",
    "#             'days':'all'\n",
    "#         }\n",
    "\n",
    "#         time_=json.dumps([time_st])\n",
    "# #     #**************\n",
    "#     def gu(luc):\n",
    "#         google_url_for_location=\"https://www.google.com/search?q=\"+luc+\"&oq=\"+luc+\"&num=1\"\n",
    "#         time.sleep(randint(0,3))\n",
    "#         driver.get(google_url_for_location)\n",
    "#         time.sleep(4)\n",
    "#         try:\n",
    "#             google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "#         except:\n",
    "#             try:\n",
    "#                 google_map_url=driver.find_element_by_class_name('Xm7sWb').click()\n",
    "#             except:\n",
    "#                 google_map_url=driver.find_element_by_class_name('Lx2b0d').click()\n",
    "#         time.sleep(1)\n",
    "#         google_map_url=driver.current_url\n",
    "# #                 print(google_map_url)\n",
    "#         return(google_map_url)\n",
    "#         ######################################\n",
    "#     def get_google_map_url(location):\n",
    "#         try:\n",
    "#             return(gu(location))\n",
    "#         except:\n",
    "#             try:\n",
    "#                 return(gu(location+', University of Michigan'))\n",
    "#             except:\n",
    "#                 sha=location.split(',')\n",
    "#                 try:\n",
    "#                     gu(sha[-3])\n",
    "#                 except:\n",
    "#                     try:\n",
    "#                         gu(sha[-2])\n",
    "#                     except:\n",
    "#                         try:\n",
    "#                             gu(sha[-1])\n",
    "#                         except Exception as e:\n",
    "#                             print(location, \"; url didn't go through\")\n",
    "#                             print(e)\n",
    "#                             return(\"\")\n",
    "\n",
    "\n",
    "#     def countr(locale):\n",
    "#         try:\n",
    "#             google_url_for_location=\"https://www.google.com/search?q=\"+locale+\"&oq=\"+locale+\"&num=1\"\n",
    "#             time.sleep(randint(0,3))\n",
    "#             driver.get(google_url_for_location)\n",
    "#             time.sleep(4)\n",
    "#             try:\n",
    "#                 google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "#             except:\n",
    "#                 try:\n",
    "#                     google_map_url=driver.find_element_by_class_name('Xm7sWb').click()\n",
    "#                 except:\n",
    "#                     try:\n",
    "#                         google_map_url=driver.find_element_by_class_name('Lx2b0d').click()\n",
    "#                     except:\n",
    "#                         locale=locale+', University of Michigan'\n",
    "#                         google_url_for_location=\"https://www.google.com/search?q=\"+locale+\"&oq=\"+locale+\"&num=1\"\n",
    "#                         time.sleep(randint(0,3))\n",
    "#                         driver.get(google_url_for_location)\n",
    "#                         time.sleep(4)\n",
    "#                         google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "#             time.sleep(1)\n",
    "#             try:\n",
    "#                 country=driver.find_element_by_class_name('x3AX1-LfntMc-header-title-VdSJob').text\n",
    "#             except:\n",
    "#                 country=driver.find_element_by_class_name('bwoZTb').text\n",
    "# #                 print(country)\n",
    "#             return(country)\n",
    "#         except Exception as e:\n",
    "#             print(locale, \";country didn't go through\")\n",
    "#             print(e)\n",
    "#             return(\"\")\n",
    "\n",
    "#     try:\n",
    "#         loc=' '.join(soupn.find('div',{'class':re.compile('field field-name-field-event-venue.+')}).find('span',{'class':'field-item-single'}).text.split())\n",
    "#     except:\n",
    "#         loc=''\n",
    "\n",
    "#     org_name='University of Oxford'\n",
    "#     org_web='https://www.ox.ac.uk/'\n",
    "#     org_pro='Oxford has a distinctive collegiate structure. Students and academics benefit from belonging both to the University, a large, internationally-renowned institution, and to a college or hall, a small, interdisciplinary academic community.'\n",
    "#     logo=''    \n",
    "#     sponsor=''\n",
    "#     agendalist=''\n",
    "#     type_=''\n",
    "#     category=''\n",
    "#     Speakerlist='' \n",
    "\n",
    "#     try:\n",
    "#         mail_=json.dumps[' '.join(soupn.find('div',{'class':re.compile('field field-name-field-contact-email.+')}).text.split())]\n",
    "#     except:\n",
    "#         mail_=''\n",
    "#     if 'nline' in loc or 'ff Campus' in loc or loc=='' or loc==' ' or loc=='-' or loc=='Virtual' or 'nspecified' in loc or 'irtual' in loc:\n",
    "#         on_off='1'\n",
    "#         city=''\n",
    "#         venue=''\n",
    "#         country=''\n",
    "#         googlePlaceUrl=''\n",
    "#     else:\n",
    "#         on_off='0'\n",
    "#         if ',' in loc:\n",
    "#             city=loc.split(',')[-2].strip()\n",
    "#             country=loc.split(',')[-1].strip()\n",
    "#         else:\n",
    "#             city=loc.split()[-3]\n",
    "#             country=countr(city)\n",
    "#         venue=loc\n",
    "#         googlePlaceUrl=get_google_map_url(venue)\n",
    "\n",
    "\n",
    "#     unox.append([link,title,start_date,end_date,time_,event_info,ticket_list,\n",
    "#                  org_pro,org_name,org_web,logo,sponsor,agendalist,\n",
    "#                  type_,category,city,country,venue,event_web,googlePlaceUrl,mail_,\n",
    "#                  Speakerlist,on_off])\n",
    "\n",
    "# unox    \n",
    "# #print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0556c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d5969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8452df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(1,31):\n",
    "#     time.sleep(1)\n",
    "#     driver.switch_to.window(driver.window_handles[k])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
