{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f5df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Feb  8 15:45:44 2022\n",
    "\n",
    "@author: ChewingGumKing_OJF\n",
    "\"\"\"\n",
    "\n",
    "#loads necessary libraries\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "#import pyautogui\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "#import shutil\n",
    "#import glob\n",
    "import os\n",
    "import warnings\n",
    "#import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyperclip as pc\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from random import randint\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "#import sys\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e886931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a new window, load the website and logs in\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\840 g3\\Desktop\\chromedriver.exe')\n",
    "\n",
    "\n",
    "RL = 'https://events.tc.umn.edu/all'\n",
    "driver.get(RL)\n",
    "try:\n",
    "    driver.maximize_window()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec70ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/p/a[2]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6548686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = bs(html,'lxml')\n",
    "allItems= soup.find_all('div',{'class':'lw_cal_event_info'})\n",
    "umtc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b79e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in allItems:\n",
    "    try:\n",
    "        web=s.find('div',{'class':'lw_events_title heading heading-2'}).find('a')['href']\n",
    "    except:\n",
    "        web=s.find('a')['href']\n",
    "    link='https://events.tc.umn.edu'+web\n",
    "    #########################\n",
    "    try:\n",
    "        tim_tease=s.find('div',{'class':'lw_events_time heading heading-3'}).text\n",
    "    except:\n",
    "        tim_tease=''\n",
    "    ###############################\n",
    "    try:\n",
    "        info_tease=s.find('p',{'class':'lw_events_summary'}).text.replace('\\n','').strip()\n",
    "        \n",
    "    except:\n",
    "        try:\n",
    "            info_tease=s.find('span',{'style':'font-weight: 400;'}).text.replace('\\n','').strip()\n",
    "        except:\n",
    "            info_tease=''\n",
    "    ##############################################\n",
    "    if tim_tease=='All Day':\n",
    "        time_spl=''\n",
    "\n",
    "    elif tim_tease =='':\n",
    "        time_spl=''\n",
    "\n",
    "    elif 'Weekly' in tim_tease:\n",
    "        time_spl=tim_tease.split('Weekly')[0].strip()\n",
    "\n",
    "    elif 'Daily' in tim_tease:\n",
    "        time_spl=tim_tease.split('Daily')[0].strip()\n",
    "\n",
    "    elif 'Monthly' in tim_tease:\n",
    "        time_spl=tim_tease.split('Monthly')[0].strip()\n",
    "\n",
    "    elif 'Yearly' in tim_tease:\n",
    "        time_spl=tim_tease.split('Yearly')[0].strip()\n",
    "\n",
    "    elif ('All' and 'to') in tim_tease:\n",
    "        time_spl=''\n",
    "\n",
    "    elif 'M-F' in tim_tease:\n",
    "        time_spl=tim_tease.split('M-F')[0].strip()\n",
    "\n",
    "    else:\n",
    "        time_spl=tim_tease\n",
    "    ##\n",
    "    if time_spl=='':\n",
    "        time_st=''\n",
    "    else:\n",
    "        zepler=time_spl.replace(' - ',' ').split(' ')\n",
    "        if len(zepler)<=2:\n",
    "            time_st={'type': 'general',\n",
    "                      'start_time':zepler[0],\n",
    "                      'end_time': '',\n",
    "                      'timezone': zepler[-1],\n",
    "                      'days': 'all'}\n",
    "        elif len(zepler)==3:\n",
    "            time_st={'type': 'general',\n",
    "                      'start_time':zepler[0],\n",
    "                      'end_time': zepler[1],\n",
    "                      'timezone': zepler[-1],\n",
    "                      'days': 'all'}\n",
    "\n",
    "        elif len(zepler)>3:\n",
    "            time_st={'type': 'general',\n",
    "                      'start_time':zepler[0],\n",
    "                      'end_time': zepler[1],\n",
    "                      'timezone': zepler[-1],\n",
    "                      'days': 'all'}\n",
    "        else:\n",
    "            time_st=''\n",
    "    \n",
    "    ###\n",
    "    if time_st=='':\n",
    "        time_=''\n",
    "    else:\n",
    "        time_=json.dumps(time_st)\n",
    "    ##############################\n",
    "    ######################\n",
    "    ####################\n",
    "    \n",
    "    driver.get(link)\n",
    "    htmln = driver.page_source\n",
    "    soupn = bs(htmln,'lxml')\n",
    "    items= soupn.find('div',{'id':'lw_cal_events'})\n",
    "    lftitems= soupn.find('div',{'id':'lw_cal_event_leftcol'})\n",
    "    try:\n",
    "        title=items.find('h2',{'class':'lw_events_title heading heading-2'}).text\n",
    "    except:\n",
    "        title=''\n",
    "    ##############################\n",
    "    try:\n",
    "        even=lftitems.find('a',{'class':'lw_join_online umn-button-regular'})['href']\n",
    "    except:\n",
    "        even=''\n",
    "    if even=='':\n",
    "        event_web=link\n",
    "    else:\n",
    "        event_web=even\n",
    "    ###################################\n",
    "    #double check\n",
    "    try:\n",
    "        if lftitems.find('h3',{'class':'heading heading-3'}).text =='Contact Info:':\n",
    "            sinzu=lftitems.find('p').text\n",
    "            if '@' in sinzu:\n",
    "                sin=sinzu\n",
    "            else:\n",
    "                sin=''\n",
    "        else:\n",
    "            sin=''\n",
    "        if sin !='':    \n",
    "            money=sin.split('\\n')\n",
    "            for mas in money:\n",
    "                if '@' in mas:\n",
    "                    mail_=mas\n",
    "        else:\n",
    "            mail_=''\n",
    "    except:\n",
    "        mail_=''\n",
    "    ###############################    \n",
    "    #on_off\n",
    "    try:\n",
    "        onner=items.find('div',{'class':'location_marker_container'}).text.replace('\\n','')\n",
    "    except:\n",
    "        onner=''\n",
    "    if ('Online'or 'online') in onner:\n",
    "        on_off='1'\n",
    "    else:\n",
    "        on_off='0'\n",
    "    ###############################\n",
    "    try:\n",
    "        event_info=items.find('div',{'class':'location_marker_container'}).text.replace('\\n','')\n",
    "    except:\n",
    "        if info_tease != '':\n",
    "            event_info=info_tease\n",
    "        else:\n",
    "            event_info=''\n",
    "            \n",
    "    ###################################\n",
    "    zazu=items.find_all('span',{'class':'event_info_label'})\n",
    "    zeh=len(zazu)\n",
    "    for n in range(1,zeh+1):\n",
    "        try:\n",
    "            if driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]/span').text=='Time:':\n",
    "                tim_dur=driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]').text.split(': ')[1]\n",
    "        except NoSuchElementException:\n",
    "            tim_dur=''\n",
    "\n",
    "        try:\n",
    "            if driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]/span').text=='Date:':\n",
    "                dat_dur=driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]').text.split(': ')[1]\n",
    "        except NoSuchElementException:\n",
    "            dat_dur=''\n",
    "\n",
    "        try:\n",
    "            if driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]/span').text=='Location:':\n",
    "                ven=driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]').text.split(': ')[1]\n",
    "        except NoSuchElementException:\n",
    "            ven=''\n",
    "        #price    \n",
    "        try:\n",
    "            if driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]/span').text=='Price:':\n",
    "                price=driver.find_element_by_xpath(f'/html/body/div/div[4]/div/div/div/div[1]/div[2]/div[2]/div/div[2]/div[3]/div[{n}]').text.split(': ')[1]\n",
    "        except NoSuchElementException:\n",
    "            price=''\n",
    "    ####################################\n",
    "    if on_off=='1':\n",
    "        venue=''\n",
    "        city=''\n",
    "        country=''\n",
    "    elif on_off=='0':\n",
    "        venue=ven\n",
    "        city=ven\n",
    "        country=\"USA\"\n",
    "    ####################################\n",
    "    if dat_dur != '':\n",
    "        yr=str(date.today().year)\n",
    "        if '-' in dat_dur:\n",
    "            sup=dat_dur.split('-')\n",
    "            spl=[q.strip()+' '+yr for q in sup]\n",
    "            spl_dt_obj = [datetime.strptime(v, '%b %d %Y') for v in spl]\n",
    "            date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "        else:\n",
    "            sup=[dat_dur, dat_dur]\n",
    "            spl=[q.strip()+' '+yr for q in sup]\n",
    "            spl_dt_obj = [datetime.strptime(v, '%b %d %Y') for v in spl]\n",
    "            date_= [z.strftime('%Y-%m-%d') for z in spl_dt_obj]\n",
    "\n",
    "    else:\n",
    "        date_=''\n",
    "\n",
    "    if date=='':\n",
    "        start_date=end_date=''\n",
    "    else:\n",
    "        start_date=date_[0]\n",
    "        end_date=date_[1]\n",
    "    ############################################\n",
    "    ticket_list=''\n",
    "    org_name='University of Minnesota Twin Cities'\n",
    "    org_web='https://twin-cities.umn.edu/'\n",
    "    org_pro=''\n",
    "    logo=''    \n",
    "    sponsor=''\n",
    "    agendalist=''\n",
    "    type_=''\n",
    "    category=''\n",
    "    Speakerlist=''  \n",
    "        \n",
    "        ######################################\n",
    "    def get_google_map_url(location):\n",
    "        try:\n",
    "            google_url_for_location=\"https://www.google.com/search?q=\"+location+\"&oq=\"+location+\"&num=1\"\n",
    "            time.sleep(randint(0,3))\n",
    "            driver.get(google_url_for_location)\n",
    "            google_map_url=driver.find_element_by_id('lu_map').click()\n",
    "            time.sleep(1)\n",
    "            google_map_url=driver.current_url\n",
    "            return(google_map_url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return(\"\")\n",
    "        \n",
    "    if venue!='':\n",
    "        googlePlaceUrl=get_google_map_url(venue)\n",
    "    else:\n",
    "        googlePlaceUrl=''\n",
    "        ############\n",
    "    umtc.append([link,title,start_date,end_date,time_,event_info,ticket_list,\n",
    "                 org_pro,org_name,org_web,logo,sponsor,agendalist,\n",
    "                 type_,category,city,country,venue,event_web,googlePlaceUrl,mail_,\n",
    "                 Speakerlist,on_off])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6fece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12:00pm CDT'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tim_tease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3334e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e128fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "umtc_dict=umtc\n",
    "\n",
    "\n",
    "umtc_df= pd.DataFrame(columns=['scrappedUrl','eventname','startdate','enddate','timing','eventinfo','ticketlist','orgProfile','orgName','orgWeb','logo','sponsor','agendalist','type','category','city','country','venue','event_website','googlePlaceUrl','ContactMail','Speakerlist','online_event'],data=umtc_dict)\n",
    "umtc_df.to_csv(\"umtc.tsv\", sep = '\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff228c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
